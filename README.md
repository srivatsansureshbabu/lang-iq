# LangIQ  
_On-Device English â†” Tamil Translation for Low-Connectivity Environments_  

![LangIQ Logo Placeholder](https://via.placeholder.com/600x200?text=LangIQ)  

## ğŸ“Œ Overview  
**LangIQ** is an **offline English â†” Tamil translation model** designed for scenarios where **internet connectivity is unreliable or unavailable**. Unlike cloud-based translation solutions, LangIQ runs **fully on-device** â€” making it perfect for **remote regions, disaster zones, or edge devices** like **Raspberry Pi** and **low-end smartphones**.  

The model is based on **MarianMT** (Hugging Face Transformers) and has been **optimized for edge deployment** through **quantization and memory reduction techniques**, while improving translation accuracy.  

---

## âœ¨ Key Features  
âœ… **Offline Translation** â€“ Works without Wi-Fi or cellular data  
âœ… **Optimized for Edge Devices** â€“ Runs on **Raspberry Pi**, low-end Android phones, and embedded systems  
âœ… **Compact Model Size** â€“ Reduced from **308 MB â†’ 198 MB**  
âœ… **Accuracy Boost** â€“ BLEU score improved by **79%** after optimizations  
âœ… **Energy Efficient** â€“ Designed for low-power devices  

---

## ğŸ› ï¸ Technical Details  

| Component            | Details                                    |
|----------------------|--------------------------------------------|
| **Base Model**       | MarianMT (Hugging Face Transformers)      |
| **Languages**        | English â†” Tamil                           |
| **Original Size**    | 308 MB                                   |
| **Optimized Size**   | ~198 MB                                  |
| **Optimization**      | Quantization, Beam Search                |
| **Target Platforms**  | Raspberry Pi, REVVL 7 (Snapdragon), Rubiks Pi 3 |
| **Metrics**          | BLEU, Memory Footprint                   |

### Why the BLEU Boost After Quantization?  
Quantization not only reduced the memory footprint but **rounded approximation values closer to the correct values**, resulting in better translations. For example:  

1.7 â†’ 2 âœ… (Correct choice)

This rounding effect significantly improved accuracy while lowering resource usage.  

---

## ğŸ“Š Performance Metrics  
- **BLEU Score**: â†‘ **79% improvement** after quantization  
- **Model Size**: â†“ from **308 MB â†’ 198 MB**  
- **Latency**: TBD (in progress for edge devices)  

---

## ğŸš€ Deployment Plan  
LangIQ is currently in the optimization phase for **on-device deployment**. The roadmap includes:  
- âœ… Fine-tuning MarianMT for Tamil-English translations  
- âœ… Applying quantization for memory reduction  
- ğŸ”„ **Deploy on Raspberry Pi 4 & Pi 3**  
- ğŸ”„ **Deploy on REVVL 7 (Snapdragon)**  
- ğŸ”„ Build **lightweight inference API**  
- ğŸ”„ Build **mobile UI for offline use**  

---

## ğŸ§ª How to Run (WIP)  
Currently, the model loads from Hugging Face and can be fine-tuned/quantized locally. Deployment scripts for Raspberry Pi and Android will be added soon.  

---

## ğŸ“Œ Roadmap  
- [x] Fine-tune MarianMT for Tamil  
- [x] Quantize for edge optimization  
- [ ] Save & load quantized model without performance loss  
- [ ] Raspberry Pi deployment guide  
- [ ] Android (Snapdragon) deployment  
- [ ] Offline mobile app (Flutter / React Native)  

---

## ğŸ“· Architecture  
English â†” Tamil Text â†’ Tokenizer â†’ MarianMT Transformer â†’ Quantized Model â†’ Edge Deployment


---

## ğŸ”® Future Goals  
- Build **speech-to-text + translation pipeline**  
- Create **fully offline messaging app with translation support**  
